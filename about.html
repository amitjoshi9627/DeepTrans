<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="Affordable and professional web design">
	  <meta name="keywords" content="web design, affordable web design, professional web design">
  	<meta name="author" content="Brad Traversy">
    <title>Artificial Neural Translator | About</title>
    <link rel="stylesheet" href="./css/style.css">
  </head>
  <body>
    <header>
      <div class="container">
        <div id="branding">
          <h1><span class="highlight">Deep</span>Trans</h1>
        </div>
        <nav>
          <ul>
            <li><a href="index.html">Home</a></li>
            <li class="current"><a href="about.html">About</a></li>
            <li><a href="services.html">Services</a></li>
          </ul>
        </nav>
      </div>
    </header>

    <!-- <section id="newsletter">
      <div class="container">
        <h1>Subscribe To Our Newsletter</h1>
        <form>
          <input type="email" placeholder="Enter Email...">
          <button type="submit" class="button_1">Subscribe</button>
        </form>
      </div>
    </section> -->

    <section id="main">
      <div class="container">
        <article id="main-col">
          <h1 class="page-title">About Us</h1>
          <p>
            Deep learning applications appeared first in speech recognition in the 1990s.The first scientific paper on using neural networks in machine translation appeared in 2014, followed by a lot of advances in the following few years. (Large-vocabulary NMT, application to Image captioning, Subword-NMT, Multilingual NMT, Multi-Source NMT, Character-dec NMT, Zero-Resource NMT, Google, Fully Character-NMT, Zero-Shot NMT in 2017) In 2015 there was the first appearance of a NMT system in a public machine translation competition (OpenMT'15).
          </p>
          <h3>What we do</h3>
          <p class="dark">
            NMT departs from phrase-based statistical approaches that use separately engineered subcomponents.[5] Neural machine translation (NMT) is not a drastic step beyond what has been traditionally done in statistical machine translation (SMT). Its main departure is the use of vector representations ("embeddings", "continuous space representations") for words and internal states. The structure of the models is simpler than phrase-based models. There is no separate language model, translation model, and reordering model, but just a single sequence model that predicts one word at a time. However, this sequence prediction is conditioned on the entire source sentence and the entire already produced target sequence. NMT models use deep learning and representation learning.          </p>
        </article>

        <aside id="sidebar">
          <div class="dark">
            <h3>Usage</h3>
            <p>By 2016, most of the best MT systems were using neural networks. Google, Microsoft, IBM,Yandex and PROMT translation services now use NMT. Google uses Google Neural Machine Translation (GNMT) in preference to its previous statistical methods.</p>
          </div>
        </aside>
      </div>
    </section>

    <footer>
      <p>Artificial Neural Translator, Copyright &copy; 2019</p>
    </footer>
  </body>
</html>
